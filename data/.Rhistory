# If 'Cleaned' folder doesn't exist, create it - amended files are stored here
main_dir  = paste0(data_folder ,"/", todays_folder)
sub_dir =  "Cleaned"
ifelse(!dir.exists(file.path(main_dir, sub_dir)),
dir.create(file.path(main_dir, sub_dir)), FALSE)
# What is psu? and vil? vil maybe village...
psu_details <-  paste0(data_folder, "/","PSU_details.csv")
# files to store summary output
data_summary_outfile <- paste0(data_folder, "/" ,todays_folder,"/" ,
todays_folder ,"_Extended_Summary.xlsx")
weekly_summary_outfile_std <- paste0(data_folder, "/", todays_folder, "/",
todays_folder, "_MOH_Summary.csv")
weekly_summary_outfile_ext <- paste0(data_folder, "/" ,todays_folder,"/" ,
todays_folder ,"_MOH_Summary_intensive.csv")
psu_summary_report <- paste0(data_folder,"/", todays_folder, "/", todays_folder,"_CI_Summary_Report_PSU.csv" )
vil_summary_report <- paste0(data_folder,"/", todays_folder, "/", todays_folder,"_CI_Summary_Report_VIL.csv" )
# File names to be checked - exclude .csv extention
# TODO - this will need altering when know the names of the output files from Kobo.
convinience_file = "1-convenience-survey-of-children-v1-survey-export"
exam_file = "3-lymphoedema-and-scabies-examination-v3-survey-export"
lab_file = "4-initial-laboratory-results-v1-survey-export"
pos_file = "5-additional-lab-results-on-fts-positive-persons-v1-survey-export"
hh_file = "2-household-enrollment-v4-e93065d8-022f-4b8a-89df-1591a8ff4a81-survey-export"
# Generate remaining full file paths.
hh_file_path <- paste0(data_folder, "/",todays_folder,"/",hh_file,".xlsx")
convenience_file_path <- paste(data_folder, "/",todays_folder,"//",convinience_file,".xlsx")
exam_file_path <- paste(data_folder, "/",todays_folder,"//",exam_file,".xlsx" )
lab_file_path  <- paste(data_folder, "/",todays_folder,"//",lab_file,".xlsx")
pos_file_path <- paste(data_folder, "/",todays_folder,"//",pos_file,".xlsx")
return(list(hh_file_path = hh_file_path, convenience_file_path = convenience_file_path,
exam_file_path = exam_file_path, lab_file_path = lab_file_path,
pos_file_path = pos_file_path))
}
#change the folder date each day e.g. TODAYSFOLDER e.g "13_10_18"
todays_folder = folder
folder = "tester_f"
#change the folder date each day e.g. TODAYSFOLDER e.g "13_10_18"
todays_folder = folder
data_folder = "~/Documents/Data/DR/Data_summaries"
amended_folder = paste0(todays_folder,"/Cleaned")
# create file paths for each thing
file_path_list <- create_file_names(todays_folder, data_folder)
file_path_list
# create file paths for each thing
file_path_list <- create_file_names(todays_folder, data_folder)
file_path_list
amended_folder = paste0(todays_folder,"/Cleaned")
source('~/Desktop/Data_checks_functions_2.R')
# create file paths for each thing
file_path_list <- create_file_names(todays_folder, data_folder, amended_folder)
file_path_list
r
r
library("rio")
library("dplyr")
file_path_list
library(sf)
vignette(pacckage="sf")
vignette(package = "sf")
vignette("sf1")
world
library(raster)
library(spDara)
library(spData)
install.packages("spData")
install.packages("spDataLarge")
library(spData)
library(spDataLarge)
install.packages("spDataLarge")
library(spDataLarge)
names(world)
world$geom
plot(world)
summary(world)
summary(world$lifeExp)
summary(world["lifeExp"])
# can convert to sp formats and back in case what to use older packages
world_sp = as(world, Class = "Spatial")
world_sf = st_as_sf(world_sp)
plot(world[3:6])
plot(world["pop"])
world_asia = world[world$continent == "Asia",]
asia = st_union(world_asia)
plot(world["pop"], reset=FALSE)
plot(asia, add=TRUE, col="Red")
plot(world["pop"], reset=FALSE)
plot(asia, add=TRUE, col="Red")
plot(world["continent"], reset=F)
cex = sqrt(world$pop) / 10000
world_cents = st_centroid(world, of_largest = T)
plot(st_geometry(world_cents), add = T, cex = cex)
india = world[world$name_long == "India"]
india = world[world$name_long == "India", ]
plot(st_geometry(india), expandBB = c(0,0.2,0.1,1), col="gray", lwd)
plot(world_asia[0], add=T)
india = world[world$name_long == "India", ]
plot(st_geometry(india), expandBB = c(0,0.2,0.1,1), col="gray")
plot(world_asia[0], add=T)
dev.off()
india = world[world$name_long == "India", ]
plot(st_geometry(india), expandBB = c(0,0.2,0.1,1), col="gray")
plot(world_asia[0], add=T)
plot(st_geometry(india), expandBB = c(0,0.2,0.1,1), col="gray", lwd=3)
plot(world_asia[0], add=T)
install.packages(c("ggplot2", "ape", "ggmsa", "phylotools","phytools", "seqinr", "ips", "seqRFLP","lubridate", "treedater"))
install.packages(c("ggplot2", "ape", "ggmsa", "phylotools","phytools", "seqinr", "ips", "seqRFLP","lubridate", "treedater"))
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(c('Biostrings', 'annotate', 'muscle', 'treeio', 'ggtree'))
source("Functions_ifiwasincharge.R")
set.seed(5896)
#load in the data
setwd("~/Documents/GitHub/covid_surveys/Main_Survey/Trust/")
survey_data <- data.table(readRDS("covid_survey_data_trust_n_9387.RDS"))
setwd("~/Documents/GitHub/covid_surveys/Main_Survey/In_charge")
######### Setup ########
setwd("~/Documents/GitHub/covid_surveys/Main_Survey/In_charge/")
source("Functions_ifiwasincharge.R")
set.seed(5896)
#load in the data
setwd("~/Documents/GitHub/covid_surveys/Main_Survey/Trust/")
survey_data <- data.table(readRDS("covid_survey_data_trust_n_9387.RDS"))
setwd("~/Documents/GitHub/covid_surveys/Main_Survey/In_charge")
#Age - categorical into broader groups
survey_data[ age == "20-24" | age == "25-29" | age == "30-34", age_group := "20-34"]
survey_data[ age == "35-39" | age == "40-44" | age == "45-49" | age == "50-54", age_group := "35-54"]
survey_data[ age == "55-59" | age == "60-64" | age == "65-69", age_group := "55-69"]
survey_data[ age == "70-74" | age == "75-79" | age == "80+", age_group := "70+"]
# remove all participants under the age of 20
survey_data <- survey_data[!is.na(age_group),]
# depression groupings - yes, no or unknown. *yes more than half the days +
survey_data[ depression == "Not at all" | depression == "Several days",
depression_group := "No"]
survey_data[ depression == "Everyday" | depression == "More than half the days",
depression_group := "Yes"]
survey_data[ is.na(depression) | depression == "",
depression_group := "Unknown"]
#Education - create broader groups
survey_data[ education == "Completed Primary School" | education == "GCSE/O-levels",
education_group := "Primary/GCSE"]
survey_data[ education == "A level/Higher" | education == "Further education",
education_group := "Alevel/Further"]
survey_data[ education == "University (first) degree" | education == "Post-graduate degree",
education_group := "University"]
survey_data[ education == "Donâ€™t know" | education == "Prefer not to say" | is.na(education) |
education == "",
education_group := "Unknown"]
# revert to data frame for modelling analysis
survey_data <- data.frame(survey_data)
# process the data for model input
processed <-textProcessor(survey_data$if_i_was_in_charge, metadata = survey_data)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta,
lower.thresh = 15) # only include words that appear at least 15 times
docs <- out$documents
vocab <- out$vocab
meta <- out$meta
# Run the stm.
surveyPrevFit <- stm(documents = out$documents,
vocab = out$vocab, K = 12,
prevalence =~  income + age_group + gender + education_group +
depression_group,
content = ~education_group,
max.em.its = 100, data = out$meta,
init.type = "Spectral")
# Note - these will need changing if anythin in the model changes
topic_labels <- c( "Returning to work / shielding",
"Lockdown enforcement",
"Nothing else",
"Test and trace",
"Expert advice",
"Lockdown severity",
"NHS / PPE",
"Testing, follow country egs",
"Travel",
"Long term consequences",
"Government response / Don't know",
"Equiptment availability")
# copy of label with colons.
topic_labels_2 <- sapply(topic_labels, function(x) paste0(x, ": "))
# topic correlations
mod.out.coor <- topicCorr(surveyPrevFit, method = "simple", cutoff = 0.01)
mod.out.coor
# topic correlations
mod.out.coor <- topicCorr(surveyPrevFit, method = "simple", cutoff = 0.02)
plot(mod.out.coor, vlabels = topic_labels, vertex.label.cex = 1.5)
# topic correlations
mod.out.coor <- topicCorr(surveyPrevFit, method = "simple", cutoff = 0.03)
plot(mod.out.coor, vlabels = topic_labels, vertex.label.cex = 1.5)
mod.out.coor
# topic correlations
mod.out.coor <- topicCorr(surveyPrevFit, method = "simple", cutoff = 0.05)
plot(mod.out.coor, vlabels = topic_labels, vertex.label.cex = 1.5)
# run the function to create an overall distribution for los in China, General Hopsital
general_samples_china <- create_dist_weibull_discrete(los_general_china_s,
sizes,
sample_size = sample_size,
init_values = c(3,27))
setwd("~/Documents/GitHub/los_review/code/")
# Load the functions
source("comb_dist_funcs.R")
#Load and format the data
source("comb_dist_data.R")
# interquatile range. Can change to something else but have to do equivalent in qunatiles
iqr <- c(0.25,0.5,0.75)
sample_size <- 100000 # sample_size is for sampling th overall, combined distribution
set.seed(643)
# run the function to create an overall distribution for los in China, General Hopsital
general_samples_china <- create_dist_weibull_discrete(los_general_china_s,
sizes,
sample_size = sample_size,
init_values = c(3,27))
# for los in rest of world, General Hopsital
general_samples_world <- create_dist_weibull_discrete(los_general_world_s,
sizes,
sample_size = sample_size,
init_values = c(3,27))
general_samples_china
sizes
# run the function to create an overall distribution for los in China, General Hopsital
general_samples_china <- create_dist_weibull_discrete(los_general_china_s,
sizes,
sample_size = sample_size,
init_values = c(3,27))
# run the function to create an overall distribution for los in China, General Hopsital
general_samples_china <- create_dist_weibull_discrete(los_general_china_s,
sample_size = sample_size,
init_values = c(3,27))
#calculate the overall sample
create_dist_weibull_discrete <- function(quants, sample_size=10000, init_values,
weighting = TRUE){
# for subset that contains medians
quants_iqr <- quants[which(!is.na(quants$LOS_med)),]
quants_mean <- quants[which(is.na(quants$LOS_med)),]
# optimise the fit to dweibull for each input set
weibull_all <- apply(quants_iqr,1, function(x) optimise_quantiles(init_values = init_values,
dist_x = x))
# save the parameters and errors
weibull_pars <-   lapply(weibull_all, function(x) format_pars(x))
weibull_pars <- data.frame(matrix(unlist(weibull_pars), ncol=length(weibull_pars), byrow=F))
weibull_errors <- lapply(weibull_all, function(x) x[[2]])
weibull_errors <- unlist(weibull_errors)
# print the errors to alert the user if the errors are very big
if(dim(quants_mean)[1] >0){
# calculate the weibull paraamters from the mean and sds
weibull_means <- apply(quants_mean,1, function(x) weibull_mean(x))
#TODO add to the weibull_all list
all_dists <- cbind(weibull_means, weibull_pars) } else {
all_dists <- weibull_pars
rownames(all_dists) <- c("shape", "scale", "N")
}
#create discrete functions for each distribution
dis_weibulls <- lapply(all_dists, function(x) discrete_dist(x))
# calculate the propotional sample sizes
if (weighting == T){
all_dists["prop_samples",] <- sapply(all_dists["N",], function(x) x/sum(all_dists["N",]))
} else{
all_dists["prop_samples",] <- sapply(all_dists["N",], function(x) 1/dim(all_dists)[2])}
# sample from multinomial to determine how many targets to include
all_dists["samples_taken",] <- rmultinom(n = 1, size = sample_size, prob = all_dists["prop_samples",])
# sample from the overall distributions
all_samples <- c()
for(i in 1:length(dis_weibulls)){
# get samples from the discrete weibull for each input set
subset_samples <- dis_weibulls[[i]]$r(n = all_dists["samples_taken",i])
all_samples <- c(all_samples, subset_samples)
}
return(list(samples = all_samples, parameters = weibull_pars, errors = weibull_errors))
}
# run the function to create an overall distribution for los in China, General Hopsital
general_samples_china <- create_dist_weibull_discrete(los_general_china_s,
sample_size = sample_size,
init_values = c(3,27))
distribution_samples <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
distribution_samples
distribution_samples <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
distribution_samples
#function to create custom distributions
create_own_distribution <- function(sample_size = 10000, location, hospital){
browser()
if ( location == "China" & hospital == "General"){
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_general_china_s,
sample_size = sample_size,
init_values = c(3,27))
}
if ( location == "Rest_of_World" & hospital == "General"){
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_general_world_s,
sample_size = sample_size,
init_values = c(3,27))
}
if ( location == "Rest_of_World" & hospital == "ICU"){
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_icu_world_s,
sample_size = sample_size,
init_values = c(3,27))
}
if ( location == "China" & hospital == "ICU"){
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_icu_china_s,
sample_size = sample_size,
init_values = c(3,27))
}
return(samples_generated[["samples"]])
}
distribution_samples <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
if ( location == "China" & hospital == "General"){
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_general_china_s,
sample_size = sample_size,
init_values = c(3,27))
}
source('~/Documents/GitHub/los_review/code/comb_dist_funcs.R')
source('~/Documents/GitHub/los_review/code/comb_dist_funcs.R')
distribution_samples <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
#function to create custom distributions
create_own_distribution <- function(sample_size = 10000, location, hospital){
browser()
if ( location == "China" & hospital == "General"){
print("here")
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_general_china_s,
sample_size = sample_size,
init_values = c(3,27))
}
if ( location == "Rest_of_World" & hospital == "General"){
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_general_world_s,
sample_size = sample_size,
init_values = c(3,27))
}
if ( location == "Rest_of_World" & hospital == "ICU"){
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_icu_world_s,
sample_size = sample_size,
init_values = c(3,27))
}
if ( location == "China" & hospital == "ICU"){
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_icu_china_s,
sample_size = sample_size,
init_values = c(3,27))
}
return(samples_generated[["samples"]])
}
location
hospital
if ( location == "China" && hospital == "General"){
print("here")
# run the function to create an overall distribution for los in China, General Hopsital
samples_generated <- create_dist_weibull_discrete(los_general_china_s,
sample_size = sample_size,
init_values = c(3,27))
}
source('~/Documents/GitHub/los_review/code/comb_dist_funcs.R')
distribution_samples <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
source('~/Documents/GitHub/los_review/code/comb_dist_funcs.R')
distribution_samples <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
distribution_samples
hist(distribution_samples)
hist(distribution_samples, breaks= 50)
source('~/Documents/GitHub/los_review/code/comb_dist_funcs.R')
calculated_distribution <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
distribution_samples <- distribution_samples[["samples"]]
hist(distribution_samples, breaks= 50)
source('~/Documents/GitHub/los_review/code/comb_dist_funcs.R')
calculated_distribution <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
distribution_samples <- distribution_samples[["samples"]]
calculated_distribution <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
distribution_samples <- calculated_distribution[["samples"]]
hist(distribution_samples, breaks= 50)
calculated_distribution
calculated_distribution <- create_own_distribution(sample_size = 100000,
location = "China",
hospital = "General")
# run the function to create an overall distribution for los in China, General Hopsital
general_samples_china <- create_dist_weibull_discrete(los_general_china_s,
sample_size = sample_size,
init_values = c(3,27))
# for los in rest of world, General Hopsital
general_samples_world <- create_dist_weibull_discrete(los_general_world_s,
sample_size = sample_size,
init_values = c(3,27))
# rename columns so can use the amin function
colnames(los_icu_s) <- c("N", "LOS_med", "LOS_q25", "LOS_q75", "LOS_mean", "LOS_sd")
colnames(los_icu_china_s) <- c("N", "LOS_med", "LOS_q25", "LOS_q75", "LOS_mean", "LOS_sd")
colnames(los_icu_world_s) <- c("N", "LOS_med", "LOS_q25", "LOS_q75", "LOS_mean", "LOS_sd")
# Get samples for ICU china
icu_samples_china <- create_dist_weibull_discrete(los_icu_china_s,
sample_size = sample_size,
init_values = c(3,27))
# Get samples for ICU rest of the world
icu_samples_world <- create_dist_weibull_discrete(los_icu_world_s,
sample_size = sample_size,
init_values = c(3,27))
# Create a histogram for the different sub_groups
HIST_PLOT <- plot_hist_1(icu_china = icu_samples_china[["samples"]],
icu_world = icu_samples_world[["samples"]],
general_china = general_samples_china[["samples"]],
general_world = general_samples_world[["samples"]])
pdf("histograms.pdf")
HIST_PLOT
dev.off()
# Calcualte the quantiles for each subgroup
quants_china_general <- quantile(general_samples_china[["samples"]], probs=iqr)
quants_china_icu <- quantile(icu_samples_china[["samples"]], probs=iqr)
quants_world_general <- quantile(general_samples_world[["samples"]],  probs=iqr)
quants_world_icu <- quantile(icu_samples_world[["samples"]],probs=iqr)
# View the % of samples that fall above the 60 xaxis cut off
china_general_over_60 <- sum(general_samples_china[["samples"]] > 60) /
length(general_samples_china[["samples"]])*100
china_icu_over_60 <- sum(icu_samples_china[["samples"]] > 60) /
length(icu_samples_china[["samples"]])*100
world_icu_over_60 <- sum(icu_samples_world[["samples"]] > 60) /
length(icu_samples_world[["samples"]])*100
world_general_over_60 <- sum(general_samples_world[["samples"]] > 60) /
length(general_samples_world[["samples"]])*100
# Generate samples only from distributions from studies where not everonye has been discharged
general_samples_china_ongoing <- create_dist_weibull_discrete(los_general_china_ongoing_s,
sizes,
sample_size = sample_size,
init_values = c(3,27))
# Generate samples only from distributions from studies where not everonye has been discharged
general_samples_china_ongoing <- create_dist_weibull_discrete(los_general_china_ongoing_s,
sample_size = sample_size,
init_values = c(3,27))
# Generate samples only from distributions from studies where everyone has been discharge
general_samples_china_complete <- create_dist_weibull_discrete(los_general_china_complete_s,
sample_size = sample_size,
init_values = c(3,27))
HIST_PLOT_2 <- plot_hist_2(china_ongoing = general_samples_china_ongoing[["samples"]],
china_complete = general_samples_china_complete[["samples"]])
pdf("histograms_complete.pdf")
HIST_PLOT_2
dev.off()
quants_china_ongoing <- quantile(general_samples_china_ongoing[["samples"]], probs=iqr)
quants_china_complete <- quantile(general_samples_china_complete[["samples"]], probs=iqr)
china_complete_over_60 <- sum(general_samples_china_complete[["samples"]] > 60) /
length(general_samples_china_complete[["samples"]])*100
china_ongoing_over_60 <- sum(general_samples_china_ongoing[["samples"]] > 60) /
length(general_samples_china_ongoing[["samples"]])*100
# Extract errors from weibull (general, china)
weibull_errors <- general_samples_china[["errors"]]
# Calculate equivalent gamma errors
gamma_errors <-  errors_gamma(los_general_china_s,
sample_size = sample_size,
init_values = c(3,27))
# combine the errors into a dataframe
all_errors <- data.frame(errors = c(weibull_errors, gamma_errors),
type = c(rep("weibull", length(weibull_errors)),
rep("gamma", length(gamma_errors))))
# save error plot
pdf("error_plot.pdf")
ERROR_PLOT <- ggplot(all_errors, aes(x=errors)) +
geom_histogram(bins=10) +
facet_grid(~type) + theme_bw()
dev.off()
# Total error in each case
sum(gamma_errors)
sum(weibull_errors)
#Rerun all the sample generations but with weighiting = False
general_samples_china_2 <- create_dist_weibull_discrete(los_general_china_s,
sample_size = sample_size,
init_values = c(3,27),
weighting = F)
general_samples_world_2 <- create_dist_weibull_discrete(los_general_world_s,
sample_size = sample_size,
init_values = c(3,27),
weighting = F)
icu_samples_china_2 <- create_dist_weibull_discrete(los_icu_china_s,
sample_size = sample_size,
init_values = c(3,27),
weighting = F)
icu_samples_world_2 <- create_dist_weibull_discrete(los_icu_world_s,
sample_size = sample_size,
init_values = c(3,27),
weighting = F)
# Create histogram of all the unweighted samplings
HIST_PLOT_NoWeight <- plot_hist_1(icu_china = icu_samples_china_2[["samples"]],
icu_world = icu_samples_world_2[["samples"]],
general_china = general_samples_china_2[["samples"]],
general_world = general_samples_world_2[["samples"]])
pdf("histograms_no_weight.pdf")
HIST_PLOT_NoWeight
dev.off()
# Create a histogram for the different sub_groups
HIST_PLOT <- plot_hist_1(icu_china = icu_samples_china[["samples"]],
icu_world = icu_samples_world[["samples"]],
general_china = general_samples_china[["samples"]],
general_world = general_samples_world[["samples"]])
HIST_PLOT
png(filename = "histogram.png")
HIST_PLOT
dev.off()
